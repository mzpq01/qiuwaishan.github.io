{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected character found when decoding 'false'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0095b5bc995c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_dataset.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/WaishanQIU/anaconda/lib/python2.7/site-packages/pandas/io/json.pyc\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit)\u001b[0m\n\u001b[1;32m    208\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    209\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WaishanQIU/anaconda/lib/python2.7/site-packages/pandas/io/json.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/WaishanQIU/anaconda/lib/python2.7/site-packages/pandas/io/json.pyc\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 495\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding 'false'"
     ]
    }
   ],
   "source": [
    "all_tweets = pd.read_json('full_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125390\n"
     ]
    }
   ],
   "source": [
    "print len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add and drop columns, reset index\n",
    "all_tweets['category'] = \"\"\n",
    "all_tweets['user_from']= \"\"\n",
    "all_tweets.reset_index(drop=True, inplace=True)\n",
    "all_tweets.drop(['data_point','raw_source','tweet_id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "prayer_dict = {'pray':'ØµÙ„Ù‰','prayer':'ØµÙ„Ø§Ø©','praying':'ØµÙ„Ø§Ø©','muslim':'Ù…Ø³Ù„Ù…','Islam':'Ø§Ù„Ø¥Ø³Ù„Ø§Ù…',\n",
    "               'mosque':'Ø¬Ø§Ù…Ø¹','mosques':'Ø¬ÙˆØ§Ù…Ø¹','masjid':'Ù…Ø³Ø§Ø¬Ø¯','masjids':'Ù…Ø³Ø¬Ø¯',\n",
    "               'call to prayer':'Ø§Ø°Ø§Ù†','muezzin':'Ù…Ø¤Ø°Ù†','holy':'Ù…Ù‚Ø¯Ø³',\n",
    "              'imam':'Ø£Ø¦Ù…Ø©','imams':'Ø§Ù…Ø§Ù…','koran':'Ø§Ù„Ù‚Ø±Ø¢Ù†','chapter':'Ø³ÙˆØ±','verse':'Ø¢ÙŠØ§Øª'}\n",
    "food_dict = {'food':'Ø·Ø¹Ø§Ù…','eating':'ÙŠØªÙ†Ø§ÙˆÙ„ Ø§Ù„Ø·Ø¹Ø§Ù…','falafel':'ÙÙ„Ø§ÙÙ„','shawarma':'Ø§Ù„Ø´Ø§ÙˆØ±Ù…Ø§',\n",
    "            'starbucks':'Ø³ØªØ§Ø±Ø¨ÙƒØ³','mcdonalds':'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²'}\n",
    "fun_dict = {'restaurant':'Ù…Ø·Ø§Ø¹Ù…','restaurants':'Ù…Ø·Ø¹Ù…','park':'Ø­Ø¯Ø§Ø¦Ù‚','theater':'Ø³ÙŠÙ†Ù…Ø§Øª','museum':'Ù…ØªØ§Ø­Ù',\n",
    "           'bakery':'Ù…Ø®Ø§Ø¨Ø²','gallery':'Ù…Ø¹Ø±Ø¶','fair':'Ù…Ù‡Ø±Ø¬Ø§Ù†Ø§Øª','zoo':'Ø­Ø¯ÙŠÙ‚Ø© Ø§Ù„Ø­ÙŠÙˆØ§Ù†','hotel':'ÙÙ†Ø§Ø¯Ù‚',\n",
    "           'starbucks':'Ø³ØªØ§Ø±Ø¨ÙƒØ³','mcdonalds':'Ù…Ø§ÙƒØ¯ÙˆÙ†Ø§Ù„Ø¯Ø²'}\n",
    "parking_dict = {'stop':'ÙŠÙˆÙ‚Ù','park':'ÙˆÙ‚Ù','parking lot':'Ù…ÙˆÙ‚Ù','parking':'Ù…ÙˆØ§Ù‚Ù','standing':'Ø§Ù„Ù…ÙˆØ§Ù‚Ù',\n",
    "               'street parking':'ÙŠØ±ÙƒÙ†','garage':'ÙŠØ¬Ø±Ù‘Ø´'}\n",
    "traffic_dict = {'traffic':'Ù…Ø±ÙˆØ±','underground':'Ø³Ø±Ø§','crowd':'Ø²Ø­Ù…Ø©','crowds':'Ø²Ø­Ø§Ù…','jammed':'Ø§Ø®ØªÙ†Ø§Ù‚',\n",
    "                'erupted':'Ù†Ø´Ø¨Øª','reroute':'ØªØ­ÙˆÙŠÙ„Ø©','bump':'Ù…Ø·Ø¨','pothole':'Ù…Ø·Ø¨Ø§Øª'}\n",
    "accident_dict = {'accident':'Ø­Ø§Ø¯Ø«','accidents':'Ø­ÙˆØ§Ø¯Ø«','crashes':'Ø­Ø§Ø¯Ø«Ø©','collision':'ØµØ¯Ù…','hit by':'ØµØ¯Ù…Ù†ÙŠ',\n",
    "                 'detour':'Ø§Ù†Ø¹ÙØ·Øª',\n",
    "                'wreck':'Ø®Ø±Ø¨Øª','wreckage':'Ø­Ø·Ø§Ù…'}\n",
    "transit_dict = {'bus':'Ø¨Ø§Øµ','taxi':'ØªØ§ÙƒØ³ÙŠ','taxis':'ØªØ§ÙƒØ³ÙŠØ§Øª','cab':'ØªÙƒØ³ÙŠ','limo':'Ù„ÙŠÙ…ÙˆØ²ÙŠÙ†','fare':'Ø£Ø¬Ø±Ø©',\n",
    "                'cab fee':'Ø§Ø¬Ø±Ø©','Careem':'ÙƒØ±ÙŠÙ…','Uber':'Ø§ÙˆØ¨Ø±','driver':'Ø³ÙˆØ§Ù‚','chauffeur':'Ø³Ø§Ø¦Ù‚','airport':'Ù…Ø·Ø§Ø±Ø§Øª',\n",
    "                'public transit':'Ù…ÙˆØ§ØµÙ„Ø§Øª'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for Arabic terms using unicode\n",
    "# It works on English too\n",
    "\n",
    "def count_search_terms(arabic_word):\n",
    "    j=0\n",
    "    search_term = unicode(arabic_word, encoding=\"utf-8\")\n",
    "    for row in all_tweets.itertuples():\n",
    "        if search_term.lower() in row[1].lower():\n",
    "            j+=1\n",
    "    return j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now count multiple terms at once\n",
    "# The function counts both Arabic and English versions\n",
    "\n",
    "def count_category(search_dict):\n",
    "    i=0\n",
    "    for key in search_dict:\n",
    "        count = count_search_terms(search_dict[key])\n",
    "        count = count + count_search_terms(key)\n",
    "        i+=count\n",
    "        print key + \": \" + str(count)\n",
    "    print \"category total: \" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bump: 58\n",
      "traffic: 155\n",
      "erupted: 3\n",
      "crowd: 136\n",
      "reroute: 1\n",
      "underground: 344\n",
      "jammed: 3\n",
      "crowds: 23\n",
      "pothole: 0\n",
      "category total: 723\n"
     ]
    }
   ],
   "source": [
    "count_category(traffic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing: 56\n",
      "stop: 76\n",
      "street parking: 3\n",
      "park: 581\n",
      "parking lot: 112\n",
      "garage: 0\n",
      "parking: 99\n",
      "category total: 927\n"
     ]
    }
   ],
   "source": [
    "count_category(parking_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collision: 69\n",
      "accident: 63\n",
      "crashes: 17\n",
      "wreck: 11\n",
      "hit by: 4\n",
      "accidents: 33\n",
      "detour: 1\n",
      "wreckage: 3\n",
      "category total: 201\n"
     ]
    }
   ],
   "source": [
    "count_category(accident_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi: 8\n",
      "fare: 59\n",
      "public transit: 5\n",
      "bus: 600\n",
      "driver: 434\n",
      "limo: 27\n",
      "Careem: 670\n",
      "Uber: 26\n",
      "cab fee: 2\n",
      "airport: 26\n",
      "chauffeur: 25\n",
      "cab: 68\n",
      "taxis: 0\n",
      "category total: 1950\n"
     ]
    }
   ],
   "source": [
    "count_category(transit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imam: 51\n",
      "chapter: 509\n",
      "masjids: 98\n",
      "holy: 18\n",
      "pray: 378\n",
      "mosques: 6\n",
      "muslim: 866\n",
      "mosque: 1679\n",
      "koran: 242\n",
      "verse: 71\n",
      "masjid: 55\n",
      "prayer: 519\n",
      "muezzin: 14\n",
      "imams: 197\n",
      "praying: 501\n",
      "call to prayer: 22\n",
      "Islam: 262\n",
      "category total: 5488\n"
     ]
    }
   ],
   "source": [
    "count_category(prayer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fair: 498\n",
      "hotel: 860\n",
      "park: 182\n",
      "starbucks: 4636\n",
      "mcdonalds: 262\n",
      "gallery: 509\n",
      "theater: 4\n",
      "restaurant: 686\n",
      "museum: 34\n",
      "zoo: 94\n",
      "bakery: 80\n",
      "restaurants: 445\n",
      "category total: 8290\n"
     ]
    }
   ],
   "source": [
    "count_category(fun_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function decides if category is present\n",
    "\n",
    "def has_category(tweet_content, search_dict):\n",
    "    answer = False\n",
    "#     tweet_content = unicode(tweet_content, encoding=\"utf-8\")\n",
    "    for english_word in search_dict.keys():\n",
    "        if english_word.lower() in tweet_content.lower():\n",
    "            answer = True\n",
    "    for arabic_word in search_dict.values():\n",
    "        arabic_word = unicode(arabic_word, encoding=\"utf-8\")\n",
    "        if arabic_word in tweet_content:\n",
    "            answer = True\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function checks every row and adds categories\n",
    "def fill_in_categories():\n",
    "    for tweet in all_tweets.itertuples():\n",
    "        idx = tweet[0]\n",
    "        content = all_tweets.loc[idx,'content']\n",
    "        if has_category(content, traffic_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'traffic'\n",
    "        elif has_category(content, transit_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'transit'\n",
    "        elif has_category(content, accident_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'accident'\n",
    "        elif has_category(content, parking_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'parking'\n",
    "        elif has_category(content, prayer_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'prayer'\n",
    "        elif has_category(content, fun_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'fun'\n",
    "        else:\n",
    "            all_tweets.loc[idx, 'category'] = 'none'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fill_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>user_location</th>\n",
       "      <th>category</th>\n",
       "      <th>user_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ïºƒÙïº³Ù’ïº˜Ùï»Ù’ï»”Ùïº®Ù Ø§ï»Ÿï» ÙÙ‘ï»ªÙ ï»­ÙïºƒÙïº—Ùï»®ïºÙ ïº‡Ùï»ŸÙï»´Ù’ï»ªÙ .</td>\n",
       "      <td>46.758696</td>\n",
       "      <td>24.695512</td>\n",
       "      <td>Thu Oct 08 03:09:57 +0000 2015</td>\n",
       "      <td>1624568515</td>\n",
       "      <td>Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ïº³Ùïº’Ù’ïº¤Ù€ïºï»¥Ù Ø§ï»Ÿï» ï»ªÙ ï»­Ùïº‘Ùïº¤Ùï»¤Ù’Ù€ïºªÙï»©Ù ï»‹ÙïºªÙïº©Ù ïº§Ùï» Ù’Ù€ï»˜Ùï»ª ...</td>\n",
       "      <td>46.758696</td>\n",
       "      <td>24.695512</td>\n",
       "      <td>Thu Oct 08 03:10:32 +0000 2015</td>\n",
       "      <td>1624568515</td>\n",
       "      <td>Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At ØªØ§Ø¬ Ø§Ù„ÙÙˆÙ„ ğŸ˜Œâ¤ï¸âœ‹ â€” https://t.co/hH3VDqzZnL</td>\n",
       "      <td>46.667250</td>\n",
       "      <td>24.587060</td>\n",
       "      <td>Tue Oct 13 07:19:50 +0000 2015</td>\n",
       "      <td>358790728</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Ø§ÙˆÙ„_ØªØºØ±ÙŠØ¯Ù‡_Ù„Ùƒ_Ø¹Ø§Ù…_1437\\n\\nÙŠØ§Ø±Ø¨ Ø¹Ø§Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ù„Ø§ Ù...</td>\n",
       "      <td>46.697182</td>\n",
       "      <td>24.753662</td>\n",
       "      <td>Tue Oct 13 08:40:09 +0000 2015</td>\n",
       "      <td>589186929</td>\n",
       "      <td>Saudi Arabia.Riyadh</td>\n",
       "      <td>none</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at @Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh, Riyadh ...</td>\n",
       "      <td>46.677856</td>\n",
       "      <td>24.714910</td>\n",
       "      <td>Tue Oct 13 17:08:31 +0000 2015</td>\n",
       "      <td>2580523225</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>fun</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content        lat        lon  \\\n",
       "0          ïºƒÙïº³Ù’ïº˜Ùï»Ù’ï»”Ùïº®Ù Ø§ï»Ÿï» ÙÙ‘ï»ªÙ ï»­ÙïºƒÙïº—Ùï»®ïºÙ ïº‡Ùï»ŸÙï»´Ù’ï»ªÙ .  46.758696  24.695512   \n",
       "1  ïº³Ùïº’Ù’ïº¤Ù€ïºï»¥Ù Ø§ï»Ÿï» ï»ªÙ ï»­Ùïº‘Ùïº¤Ùï»¤Ù’Ù€ïºªÙï»©Ù ï»‹ÙïºªÙïº©Ù ïº§Ùï» Ù’Ù€ï»˜Ùï»ª ...  46.758696  24.695512   \n",
       "2       At ØªØ§Ø¬ Ø§Ù„ÙÙˆÙ„ ğŸ˜Œâ¤ï¸âœ‹ â€” https://t.co/hH3VDqzZnL  46.667250  24.587060   \n",
       "3  #Ø§ÙˆÙ„_ØªØºØ±ÙŠØ¯Ù‡_Ù„Ùƒ_Ø¹Ø§Ù…_1437\\n\\nÙŠØ§Ø±Ø¨ Ø¹Ø§Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ù„Ø§ Ù...  46.697182  24.753662   \n",
       "4  I'm at @Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh, Riyadh ...  46.677856  24.714910   \n",
       "\n",
       "                             time        user           user_location  \\\n",
       "0  Thu Oct 08 03:09:57 +0000 2015  1624568515  Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡   \n",
       "1  Thu Oct 08 03:10:32 +0000 2015  1624568515  Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡   \n",
       "2  Tue Oct 13 07:19:50 +0000 2015   358790728                 Riyadh    \n",
       "3  Tue Oct 13 08:40:09 +0000 2015   589186929    Saudi Arabia.Riyadh    \n",
       "4  Tue Oct 13 17:08:31 +0000 2015  2580523225                  Riyadh   \n",
       "\n",
       "  category user_from  \n",
       "0     none            \n",
       "1     none            \n",
       "2     none            \n",
       "3     none            \n",
       "4      fun            "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets_categorized = all_tweets[all_tweets['category']!= 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_converter(input_string):\n",
    "    orig_date = input_string[:-10] + input_string[-4:]\n",
    "    convert = time.strptime(orig_date, '%a %b %d %H:%M:%S %Y')\n",
    "    new_date = time.strftime(\"%A %I %p\",convert)\n",
    "    return new_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuesday 05 PM\n"
     ]
    }
   ],
   "source": [
    "print time_converter('Tue Oct 13 17:08:31 +0000 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday 03AM\n"
     ]
    }
   ],
   "source": [
    "print time_converter(all_tweets_categorized.loc[16,'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Scott\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for row in all_tweets_categorized.itertuples():\n",
    "    idx = int(row[0])\n",
    "    new_time = time_converter(all_tweets_categorized.loc[idx,'time'])\n",
    "    all_tweets_categorized.loc[idx,'timestamp'] = new_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13280\n"
     ]
    }
   ],
   "source": [
    "print len(all_tweets_categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>user_location</th>\n",
       "      <th>category</th>\n",
       "      <th>user_from</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at @Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh, Riyadh ...</td>\n",
       "      <td>46.677856</td>\n",
       "      <td>24.714910</td>\n",
       "      <td>Tue Oct 13 17:08:31 +0000 2015</td>\n",
       "      <td>2580523225</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>fun</td>\n",
       "      <td></td>\n",
       "      <td>Tuesday 05 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm at Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh w/ @93m7m...</td>\n",
       "      <td>46.676350</td>\n",
       "      <td>24.676143</td>\n",
       "      <td>Thu Dec 03 06:51:58 +0000 2015</td>\n",
       "      <td>458461852</td>\n",
       "      <td>Ø§Ù„Ø±ÙŠØ§Ø¶</td>\n",
       "      <td>fun</td>\n",
       "      <td></td>\n",
       "      <td>Thursday 06 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@dr_fahad_harthi @ksa12300 \\nÙ‡Ù… ÙŠØ¹Ø±ÙÙˆÙ† Ø£Ù†(Ø¯Ø§Ø¹Ø´...</td>\n",
       "      <td>46.801655</td>\n",
       "      <td>24.724120</td>\n",
       "      <td>Thu Oct 08 03:26:06 +0000 2015</td>\n",
       "      <td>622140270</td>\n",
       "      <td>Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©</td>\n",
       "      <td>prayer</td>\n",
       "      <td></td>\n",
       "      <td>Thursday 03 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I'm at King Saud University | Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯...</td>\n",
       "      <td>46.632696</td>\n",
       "      <td>24.728943</td>\n",
       "      <td>Thu Dec 03 07:19:22 +0000 2015</td>\n",
       "      <td>481414929</td>\n",
       "      <td></td>\n",
       "      <td>prayer</td>\n",
       "      <td></td>\n",
       "      <td>Thursday 07 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ù…ØªØ­Ù…Ø³Ø© Ø¹Ù„Ù‰ Ù†ÙˆÙ…Ø© Ø§Ù„Ø¹ØµØ± Ù…Ù† Ø§Ù„Ø­ÙŠÙ†ğŸ˜ (at Al-Tarbia...</td>\n",
       "      <td>46.662150</td>\n",
       "      <td>24.709980</td>\n",
       "      <td>Thu Dec 03 07:21:36 +0000 2015</td>\n",
       "      <td>1337283242</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>prayer</td>\n",
       "      <td></td>\n",
       "      <td>Thursday 07 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content        lat        lon  \\\n",
       "4   I'm at @Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh, Riyadh ...  46.677856  24.714910   \n",
       "7   I'm at Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh w/ @93m7m...  46.676350  24.676143   \n",
       "16  @dr_fahad_harthi @ksa12300 \\nÙ‡Ù… ÙŠØ¹Ø±ÙÙˆÙ† Ø£Ù†(Ø¯Ø§Ø¹Ø´...  46.801655  24.724120   \n",
       "42  I'm at King Saud University | Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ù„Ùƒ Ø³Ø¹ÙˆØ¯...  46.632696  24.728943   \n",
       "46  Ù…ØªØ­Ù…Ø³Ø© Ø¹Ù„Ù‰ Ù†ÙˆÙ…Ø© Ø§Ù„Ø¹ØµØ± Ù…Ù† Ø§Ù„Ø­ÙŠÙ†ğŸ˜ (at Al-Tarbia...  46.662150  24.709980   \n",
       "\n",
       "                              time        user             user_location  \\\n",
       "4   Tue Oct 13 17:08:31 +0000 2015  2580523225                    Riyadh   \n",
       "7   Thu Dec 03 06:51:58 +0000 2015   458461852                    Ø§Ù„Ø±ÙŠØ§Ø¶   \n",
       "16  Thu Oct 08 03:26:06 +0000 2015   622140270  Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©   \n",
       "42  Thu Dec 03 07:19:22 +0000 2015   481414929                             \n",
       "46  Thu Dec 03 07:21:36 +0000 2015  1337283242                    Riyadh   \n",
       "\n",
       "   category user_from       timestamp  \n",
       "4       fun             Tuesday 05 PM  \n",
       "7       fun            Thursday 06 AM  \n",
       "16   prayer            Thursday 03 AM  \n",
       "42   prayer            Thursday 07 AM  \n",
       "46   prayer            Thursday 07 AM  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_categorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets_categorized.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets_categorized.to_csv('all_tweets_categorized.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define location based on our criteria\n",
    "# don't forget to implement .lower on the search so it ignores case\n",
    "# and prioritize more local matches over more general ones\n",
    "\n",
    "riyadh_list = ['riyadh','rhiyad','Ø§Ù„Ø±ÙŠØ§Ø¶','riyad','Ø­ÙŠ','riyad','Ø§Ù„Ø¨ÙŠØª']\n",
    "ksa_list = ['kingdom of saudi arabia','ksa','k.s.a.','saudi','saudi arabia','jeddah','mecca','dammam','medina','hofuf',\n",
    "           'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©','Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¬Ø²ÙŠØ±Ù‡ Ø§Ù„Ø¹Ø±Ø¨','Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©','Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©','makkah','madinah','tabuk']\n",
    "mideast_list = ['bahrain','manama','iran','tehran','Ø·Ù‡Ø±Ø§Ù†','iraq','baghdad','Ø¨ØºØ¯Ø§Ø¯','syria','damascus','jordan','amman',\n",
    "                'lebanon','beirut','kuwait','turkmenistan','ashgabat','tajikistan','dushanbe','kazakh','astana',\n",
    "               'oman','muscat','qatar','doha','united arab emirates','uae','kyrgyzstan','bishkek',\n",
    "               'afghanistan','kabul','armenia','yerevan','azerbaijan','baku','turkey','ankara','israel','jerusalem',\n",
    "               'istanbul','tel aviv','aleppo','mashhad','izmir','isfahan','dubai','Ø¨Ù„Ø§Ø¯ Ø§Ù„Ø¹Ø±Ø¨',\n",
    "                'abu dhabi','Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡']\n",
    "worker_list = ['philippines','pilipinas','manila','caloocan','quezon','cebu','davao',\n",
    "               'pakistan','karachi','lahore','faisalabad','multan','hyderabad','rawalpindi','punjab','pradesh',\n",
    "               'orissa','bengal','rajasthan','bihar','bangladesh','dhaka','chittagong','khulna','rajshahi',\n",
    "              'india','chennai','madras','mumbai','delhi','bangalore','kolkata','ahmedabad','surat','jaipur','pune',\n",
    "              'assam','bombay','indonesia','aceh','jakarta','surabaya','bandung','bekasi','medan','sri',\n",
    "              'egypt','cairo','Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©','alexandria','yemen','sanaa','sudan','pangasinan','malay','panang','kuala']\n",
    "              \n",
    "foreign_list = ['city','state','province','territory','village','town','ville','barcelona','california','brazil',\n",
    "             'finland','madrid','united states','america','bronx','nyc','new york','manhattan','chicago','tampa',\n",
    "             'seattle','manchester','paraguay','turin','rome','london','tokyo','japan','china','hong kong','beijing',\n",
    "               'helsinki','rio','los angeles','tx','houston','santiago','canada','vancouver','toronto','san francisco',\n",
    "               'boston','australia','melbourne','sydney','france','paris','england','harvard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_location(word):\n",
    "    j=0\n",
    "    search_term = unicode(word, encoding=\"utf-8\")\n",
    "    for row in all_tweets.itertuples():\n",
    "        if search_term in row[6]:\n",
    "            j+=1\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    51544\n",
      "Riyadh                               8835\n",
      "Riyadh, Kingdom of Saudi Arabia      3570\n",
      "Ø§Ù„Ø±ÙŠØ§Ø¶                               3318\n",
      "Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© - Ø§Ù„Ø±ÙŠØ§Ø¶ - Ø­ÙŠ Ø§Ù„Ø´ÙØ§         3216\n",
      "Riyadh, Saudi Arabia                 2854\n",
      "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© /Saudi Arabia       2733\n",
      "Saudi Arabia                         1692\n",
      "Riyadh                               1548\n",
      "Riyadh, Saudi Arabis                 1548\n",
      "Ø§Ù„Ø±ÙŠØ§Ø¶                               1141\n",
      "Riyadh Saudi Arabia                  1110\n",
      "#Madrid                              1060\n",
      "Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©              931\n",
      "Kingdom of Saudi Arabia               902\n",
      "Riyadh.                               794\n",
      "gg                                    736\n",
      "Ø§Ù„Ø±ÙŠØ§Ø¶, Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©      666\n",
      "Saudi Arabia, Riyadh                  636\n",
      "@AlNassrFC                            551\n",
      " 1994 . Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡                      532\n",
      "Saudi Arabia - Riyadh                 444\n",
      "Saudi Arabia, Riyadh                  367\n",
      "Riyadh - Saudi Arabia                 325\n",
      "Riyadh, KSA                           318\n",
      "Saudi Arabia                          294\n",
      "Riyadh, K.S.A.                        271\n",
      "Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø¨Ù„Ø§Ø¯ Ø§Ù„Ø­Ø±Ù…ÙŠÙ†                  261\n",
      "Saudi Arabia -Riyadh                  253\n",
      "riyadh                                244\n",
      "                                    ...  \n",
      "xd                                      1\n",
      "As Sarrar - Riyadh - Milano             1\n",
      "Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø§Ù„Ø§Ù…Ø±ÙŠÙƒÙŠØ©              1\n",
      "instagram: iN0rh                        1\n",
      "Tampa, FL, US                           1\n",
      "not a prisoner nor a freedman           1\n",
      "Aden, Yemen                             1\n",
      "with my cute Brazilian friend           1\n",
      "P.I. BABY!                              1\n",
      "saudi arabiaØŒRiyadh                     1\n",
      "LongBeach, CA / Sharjah, UAE            1\n",
      " Dammam , Dubai                         1\n",
      "Between Jeddah,Dubai,Amman              1\n",
      "24.672642,46.704202                     1\n",
      "instgram&kik: majid_habab               1\n",
      "Ø­ÙØ± Ø§Ù„Ø¨Ø§Ø·Ù† (Ø§Ù„Ù‚ÙŠØµÙˆÙ…Ø©)                   1\n",
      "Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡                 1\n",
      "Dhaka                                   1\n",
      "KSA.                                    1\n",
      "Venezuela                               1\n",
      "Ø§Ù„Ø¯Ù…Ø§Ù…, Ø§Ù„Ø´Ø±Ù‚ÙŠ                          1\n",
      "Ù‚Ù„Øª Ù„Ø£Ø­Ù„Ø§Ù…ÙŠ ØªØ¹Ø§Ù„ÙŠ .. ÙØªØ¹Ø§Ù„Øª             1\n",
      "Ahsa, Eastern - Riyadh.                 1\n",
      "kingdom of Saudi Arabia                 1\n",
      "Ø§Ù„Ø±ÙŠØ§Ø¶ Ø§Ù„Ø®Ø§Øµ Ù„Ù„Ø¶Ø±ÙˆØ±Ù‡                    1\n",
      "Bronx, NY                               1\n",
      " KSA Ø·Ø¨Ø¹Ø§Ù‹ ÙÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Riyadh           1\n",
      "earth                                   1\n",
      "from Davao Phils.                       1\n",
      "East Bay, CA                            1\n",
      "Name: user_location, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print all_tweets['user_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_location(user_loc, search_list):\n",
    "    answer = False\n",
    "#     user_loc = unicode(user_loc, encoding=\"utf-8\")\n",
    "    for entry in search_list:\n",
    "        entry = unicode(entry, encoding='utf-8')\n",
    "        if entry.lower() in user_loc.lower():\n",
    "            answer = True\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for tweet in all_tweets.itertuples():\n",
    "    if has_location(tweet[6], worker_list):\n",
    "        j+=1\n",
    "print j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_in_locations():\n",
    "    for tweet in all_tweets.itertuples():\n",
    "        idx = tweet[0]\n",
    "        user_loc = all_tweets.loc[idx,'user_location']\n",
    "        if user_loc == '':\n",
    "            all_tweets.loc[idx, 'user_from'] = 'None'\n",
    "        elif has_location(user_loc, foreign_list):\n",
    "            all_tweets.loc[idx, 'user_from'] = 'World'\n",
    "        elif has_location(user_loc, riyadh_list):\n",
    "            all_tweets.loc[idx, 'user_from'] = 'Riyadh'\n",
    "        elif has_location(user_loc, ksa_list):\n",
    "            all_tweets.loc[idx, 'user_from'] = 'Saudi Arabia' \n",
    "        elif has_location(user_loc, mideast_list):\n",
    "            all_tweets.loc[idx, 'user_from'] = 'Middle East'\n",
    "        elif has_location(user_loc, worker_list):\n",
    "            all_tweets.loc[idx, 'user_from'] = 'Labor'\n",
    "        else:\n",
    "            all_tweets.loc[idx, 'user_from'] = 'Unmatched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fill_in_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets_located = all_tweets[all_tweets['user_from']!= 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets_located.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_tweets_located['timestamp'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73846\n"
     ]
    }
   ],
   "source": [
    "print len(all_tweets_located)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n"
     ]
    }
   ],
   "source": [
    "for row in all_tweets_located.itertuples():\n",
    "    idx = int(row[0])\n",
    "    new_time = time_converter(all_tweets_located.loc[idx,'time'])\n",
    "    all_tweets_located.loc[idx,'timestamp'] = new_time\n",
    "    if idx%1000 == 0:\n",
    "        print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export as is\n",
    "# collapse by unique combinations of timestamp and user_from\n",
    "# sort by 'time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "      <th>user_location</th>\n",
       "      <th>category</th>\n",
       "      <th>user_from</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ïºƒÙïº³Ù’ïº˜Ùï»Ù’ï»”Ùïº®Ù Ø§ï»Ÿï» ÙÙ‘ï»ªÙ ï»­ÙïºƒÙïº—Ùï»®ïºÙ ïº‡Ùï»ŸÙï»´Ù’ï»ªÙ .</td>\n",
       "      <td>46.758696</td>\n",
       "      <td>24.695512</td>\n",
       "      <td>Thu Oct 08 03:09:57 +0000 2015</td>\n",
       "      <td>1624568515</td>\n",
       "      <td>Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡</td>\n",
       "      <td>none</td>\n",
       "      <td>Unmatched</td>\n",
       "      <td>Thursday 03 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ïº³Ùïº’Ù’ïº¤Ù€ïºï»¥Ù Ø§ï»Ÿï» ï»ªÙ ï»­Ùïº‘Ùïº¤Ùï»¤Ù’Ù€ïºªÙï»©Ù ï»‹ÙïºªÙïº©Ù ïº§Ùï» Ù’Ù€ï»˜Ùï»ª ...</td>\n",
       "      <td>46.758696</td>\n",
       "      <td>24.695512</td>\n",
       "      <td>Thu Oct 08 03:10:32 +0000 2015</td>\n",
       "      <td>1624568515</td>\n",
       "      <td>Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡</td>\n",
       "      <td>none</td>\n",
       "      <td>Unmatched</td>\n",
       "      <td>Thursday 03 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At ØªØ§Ø¬ Ø§Ù„ÙÙˆÙ„ ğŸ˜Œâ¤ï¸âœ‹ â€” https://t.co/hH3VDqzZnL</td>\n",
       "      <td>46.667250</td>\n",
       "      <td>24.587060</td>\n",
       "      <td>Tue Oct 13 07:19:50 +0000 2015</td>\n",
       "      <td>358790728</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>none</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Tuesday 07 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Ø§ÙˆÙ„_ØªØºØ±ÙŠØ¯Ù‡_Ù„Ùƒ_Ø¹Ø§Ù…_1437\\n\\nÙŠØ§Ø±Ø¨ Ø¹Ø§Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ù„Ø§ Ù...</td>\n",
       "      <td>46.697182</td>\n",
       "      <td>24.753662</td>\n",
       "      <td>Tue Oct 13 08:40:09 +0000 2015</td>\n",
       "      <td>589186929</td>\n",
       "      <td>Saudi Arabia.Riyadh</td>\n",
       "      <td>none</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Tuesday 08 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at @Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh, Riyadh ...</td>\n",
       "      <td>46.677856</td>\n",
       "      <td>24.714910</td>\n",
       "      <td>Tue Oct 13 17:08:31 +0000 2015</td>\n",
       "      <td>2580523225</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>fun</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Tuesday 05 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm at Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh w/ @93m7m...</td>\n",
       "      <td>46.676350</td>\n",
       "      <td>24.676143</td>\n",
       "      <td>Thu Dec 03 06:51:58 +0000 2015</td>\n",
       "      <td>458461852</td>\n",
       "      <td>Ø§Ù„Ø±ÙŠØ§Ø¶</td>\n",
       "      <td>fun</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Thursday 06 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Such few words on a cup of coffee on the morni...</td>\n",
       "      <td>46.676252</td>\n",
       "      <td>24.664003</td>\n",
       "      <td>Thu Dec 03 06:53:19 +0000 2015</td>\n",
       "      <td>159116932</td>\n",
       "      <td></td>\n",
       "      <td>none</td>\n",
       "      <td>Unmatched</td>\n",
       "      <td>Thursday 06 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm at Dar Al-Shifa Hospital https://t.co/Vedq...</td>\n",
       "      <td>46.703087</td>\n",
       "      <td>24.638563</td>\n",
       "      <td>Thu Dec 03 06:54:22 +0000 2015</td>\n",
       "      <td>770696682</td>\n",
       "      <td>Kingdom of Saudi Arabia</td>\n",
       "      <td>none</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Thursday 06 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'Ø¨ØµÙŠØ±ï´¾', 'ï´¿ÙˆÙ„Ùˆ' Ùˆ 'Ù„Ø¨ØºÙˆØ§' Ø§Ù„Ø¢Ù† Ù†Ø´Ø· ÙÙŠ Saudi Ar...</td>\n",
       "      <td>46.722400</td>\n",
       "      <td>24.688000</td>\n",
       "      <td>Thu Dec 03 06:54:34 +0000 2015</td>\n",
       "      <td>193981558</td>\n",
       "      <td>Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© /Saudi Arabia</td>\n",
       "      <td>none</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Thursday 06 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm at Herfy | Ù‡Ø±ÙÙŠ - @herfyfsc in Riyadh http...</td>\n",
       "      <td>46.703370</td>\n",
       "      <td>24.637801</td>\n",
       "      <td>Thu Dec 03 06:54:45 +0000 2015</td>\n",
       "      <td>770696682</td>\n",
       "      <td>Kingdom of Saudi Arabia</td>\n",
       "      <td>none</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Thursday 06 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content        lat        lon  \\\n",
       "0          ïºƒÙïº³Ù’ïº˜Ùï»Ù’ï»”Ùïº®Ù Ø§ï»Ÿï» ÙÙ‘ï»ªÙ ï»­ÙïºƒÙïº—Ùï»®ïºÙ ïº‡Ùï»ŸÙï»´Ù’ï»ªÙ .  46.758696  24.695512   \n",
       "1  ïº³Ùïº’Ù’ïº¤Ù€ïºï»¥Ù Ø§ï»Ÿï» ï»ªÙ ï»­Ùïº‘Ùïº¤Ùï»¤Ù’Ù€ïºªÙï»©Ù ï»‹ÙïºªÙïº©Ù ïº§Ùï» Ù’Ù€ï»˜Ùï»ª ...  46.758696  24.695512   \n",
       "2       At ØªØ§Ø¬ Ø§Ù„ÙÙˆÙ„ ğŸ˜Œâ¤ï¸âœ‹ â€” https://t.co/hH3VDqzZnL  46.667250  24.587060   \n",
       "3  #Ø§ÙˆÙ„_ØªØºØ±ÙŠØ¯Ù‡_Ù„Ùƒ_Ø¹Ø§Ù…_1437\\n\\nÙŠØ§Ø±Ø¨ Ø¹Ø§Ù… Ø¬Ø¯ÙŠØ¯ Ø¨Ù„Ø§ Ù...  46.697182  24.753662   \n",
       "4  I'm at @Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh, Riyadh ...  46.677856  24.714910   \n",
       "5  I'm at Starbucks | Ø³ØªØ§Ø±Ø¨ÙƒØ³ in Riyadh w/ @93m7m...  46.676350  24.676143   \n",
       "6  Such few words on a cup of coffee on the morni...  46.676252  24.664003   \n",
       "7  I'm at Dar Al-Shifa Hospital https://t.co/Vedq...  46.703087  24.638563   \n",
       "8  'Ø¨ØµÙŠØ±ï´¾', 'ï´¿ÙˆÙ„Ùˆ' Ùˆ 'Ù„Ø¨ØºÙˆØ§' Ø§Ù„Ø¢Ù† Ù†Ø´Ø· ÙÙŠ Saudi Ar...  46.722400  24.688000   \n",
       "9  I'm at Herfy | Ù‡Ø±ÙÙŠ - @herfyfsc in Riyadh http...  46.703370  24.637801   \n",
       "\n",
       "                             time        user                   user_location  \\\n",
       "0  Thu Oct 08 03:09:57 +0000 2015  1624568515          Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡   \n",
       "1  Thu Oct 08 03:10:32 +0000 2015  1624568515          Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ ÙˆØ§ØªÙˆØ¨ Ø¥Ù„ÙŠÙ‡   \n",
       "2  Tue Oct 13 07:19:50 +0000 2015   358790728                         Riyadh    \n",
       "3  Tue Oct 13 08:40:09 +0000 2015   589186929            Saudi Arabia.Riyadh    \n",
       "4  Tue Oct 13 17:08:31 +0000 2015  2580523225                          Riyadh   \n",
       "5  Thu Dec 03 06:51:58 +0000 2015   458461852                          Ø§Ù„Ø±ÙŠØ§Ø¶   \n",
       "6  Thu Dec 03 06:53:19 +0000 2015   159116932                                   \n",
       "7  Thu Dec 03 06:54:22 +0000 2015   770696682         Kingdom of Saudi Arabia   \n",
       "8  Thu Dec 03 06:54:34 +0000 2015   193981558  Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© /Saudi Arabia   \n",
       "9  Thu Dec 03 06:54:45 +0000 2015   770696682         Kingdom of Saudi Arabia   \n",
       "\n",
       "  category     user_from       timestamp  \n",
       "0     none     Unmatched  Thursday 03 AM  \n",
       "1     none     Unmatched  Thursday 03 AM  \n",
       "2     none        Riyadh   Tuesday 07 AM  \n",
       "3     none        Riyadh   Tuesday 08 AM  \n",
       "4      fun        Riyadh   Tuesday 05 PM  \n",
       "5      fun        Riyadh  Thursday 06 AM  \n",
       "6     none     Unmatched  Thursday 06 AM  \n",
       "7     none  Saudi Arabia  Thursday 06 AM  \n",
       "8     none  Saudi Arabia  Thursday 06 AM  \n",
       "9     none  Saudi Arabia  Thursday 06 AM  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_located.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets_located.to_csv('all_tweets_located.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Riyadh          46030\n",
       "Unmatched       13074\n",
       "Saudi Arabia     9410\n",
       "World            3150\n",
       "Middle East      1244\n",
       "Labor             938\n",
       "Name: user_from, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_located['user_from'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "located_tweets_counter = all_tweets_located.drop(['content','lat','lon','time','user_location','user','category'],axis=1)\n",
    "located_tweets_counter['counter'] = 1\n",
    "collapse_by_time = located_tweets_counter.groupby(['user_from','timestamp']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collapse_by_time.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_from</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 01 AM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 01 PM</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 02 AM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 02 PM</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 03 AM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 03 PM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 04 PM</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 05 AM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 05 PM</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Labor</td>\n",
       "      <td>Friday 06 AM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_from     timestamp  counter\n",
       "0     Labor  Friday 01 AM        1\n",
       "1     Labor  Friday 01 PM        9\n",
       "2     Labor  Friday 02 AM        3\n",
       "3     Labor  Friday 02 PM        7\n",
       "4     Labor  Friday 03 AM        2\n",
       "5     Labor  Friday 03 PM        4\n",
       "6     Labor  Friday 04 PM        7\n",
       "7     Labor  Friday 05 AM        3\n",
       "8     Labor  Friday 05 PM       13\n",
       "9     Labor  Friday 06 AM        4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_by_time.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapse_by_time['day']=''\n",
    "collapse_by_time['hour']=''\n",
    "collapse_by_time['meridian']=''\n",
    "collapse_by_time['week_order'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for row in collapse_by_time.itertuples():\n",
    "    idx = row[0]\n",
    "    stamp = collapse_by_time.loc[idx,'timestamp']\n",
    "    day = stamp[:-6]\n",
    "    hour = stamp[-5:-3]\n",
    "    meridian = stamp[-2:]\n",
    "    collapse_by_time.loc[idx,'day'] = day\n",
    "    collapse_by_time.loc[idx,'hour'] = hour\n",
    "    collapse_by_time.loc[idx,'meridian'] = meridian\n",
    "    if idx%100 == 0:\n",
    "        print idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in collapse_by_time.itertuples():\n",
    "    idx = row[0]\n",
    "    day = collapse_by_time.loc[idx,'day']\n",
    "    if day == 'Sunday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 1\n",
    "    elif day == 'Monday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 2\n",
    "    elif day == 'Tuesday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 3\n",
    "    elif day == 'Wednesday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 4\n",
    "    elif day == 'Thursday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 5\n",
    "    elif day == 'Friday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 6\n",
    "    elif day == 'Saturday':\n",
    "        collapse_by_time.loc[idx,'week_order'] = 7\n",
    "    else:\n",
    "        collapse_by_time.loc[idx,'week_order'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "collapse_by_time_sorted = collapse_by_time.sort(columns=['week_order','meridian','hour'])\n",
    "collapse_by_time_sorted.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapse_by_time_sorted.to_csv('location_collapsed.csv', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
