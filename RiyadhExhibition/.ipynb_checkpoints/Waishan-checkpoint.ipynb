{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total file number is: 23459\n",
      "Need Loop for almost 27 times.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Categorize and write CSV of Tweets Data\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "path = 'json/'\n",
    "files = os.listdir(path)\n",
    "all_files = []\n",
    "# print files\n",
    "for f in files:\n",
    "    if f.endswith(\".json\"):\n",
    "        all_files.append(f)\n",
    "count_files = len(all_files)\n",
    "print \"Total file number is: \" + str(count_files)\n",
    "times = count_files/280/3\n",
    "print \"Need Loop for almost \" + str(times) + \" times.\" + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(16800, 17640)\n",
      "(48672, 9)\n",
      "Done Writing: df_new_16800_17640.csv\n",
      "21\n",
      "(17640, 18480)\n",
      "(53151, 9)\n",
      "Done Writing: df_new_17640_18480.csv\n",
      "22\n",
      "(18480, 19320)\n",
      "(55505, 9)\n",
      "Done Writing: df_new_18480_19320.csv\n",
      "23\n",
      "(19320, 20160)\n",
      "(51616, 9)\n",
      "Done Writing: df_new_19320_20160.csv\n",
      "24\n",
      "(20160, 21000)\n",
      "(56914, 9)\n",
      "Done Writing: df_new_20160_21000.csv\n",
      "25\n",
      "(21000, 21840)\n",
      "(55922, 9)\n",
      "Done Writing: df_new_21000_21840.csv\n",
      "26\n",
      "(21840, 22680)\n",
      "(53597, 9)\n",
      "Done Writing: df_new_21840_22680.csv\n",
      "27\n",
      "(22680, 23520)\n",
      "(51766, 9)\n",
      "Done Writing: df_new_22680_23520.csv\n"
     ]
    }
   ],
   "source": [
    "prayer_dict = {'pray':'صلى','prayer':'صلاة','praying':'صلاة','muslim':'مسلم','Islam':'الإسلام',\n",
    "               'mosque':'جامع','mosques':'جوامع','masjid':'مساجد','masjids':'مسجد',\n",
    "               'call to prayer':'اذان','muezzin':'مؤذن','holy':'مقدس',\n",
    "              'imam':'أئمة','imams':'امام','koran':'القرآن','chapter':'سور','verse':'آيات'}\n",
    "food_dict = {'food':'طعام','eating':'يتناول الطعام','falafel':'فلافل','shawarma':'الشاورما',\n",
    "            'starbucks':'ستاربكس','mcdonalds':'ماكدونالدز'}\n",
    "fun_dict = {'restaurant':'مطاعم','restaurants':'مطعم','park':'حدائق','theater':'سينمات','museum':'متاحف',\n",
    "           'bakery':'مخابز','gallery':'معرض','fair':'مهرجانات','zoo':'حديقة الحيوان','hotel':'فنادق',\n",
    "           'starbucks':'ستاربكس','mcdonalds':'ماكدونالدز'}\n",
    "parking_dict = {'stop':'يوقف','park':'وقف','parking lot':'موقف','parking':'مواقف','standing':'المواقف',\n",
    "               'street parking':'يركن','garage':'يجرّش'}\n",
    "traffic_dict = {'traffic':'مرور','underground':'سرا','crowd':'زحمة','crowds':'زحام','jammed':'اختناق',\n",
    "                'erupted':'نشبت','reroute':'تحويلة','bump':'مطب','pothole':'مطبات'}\n",
    "accident_dict = {'accident':'حادث','accidents':'حوادث','crashes':'حادثة','collision':'صدم','hit by':'صدمني',\n",
    "                 'detour':'انعفطت',\n",
    "                'wreck':'خربت','wreckage':'حطام'}\n",
    "transit_dict = {'bus':'باص','taxi':'تاكسي','taxis':'تاكسيات','cab':'تكسي','limo':'ليموزين','fare':'أجرة',\n",
    "                'cab fee':'اجرة','Careem':'كريم','Uber':'اوبر','driver':'سواق','chauffeur':'سائق','airport':'مطارات',\n",
    "                'public transit':'مواصلات'}\n",
    "# Search for Arabic terms using unicode\n",
    "# It works on English too\n",
    "\n",
    "def count_search_terms(arabic_word):\n",
    "    j=0\n",
    "    search_term = unicode(arabic_word, encoding=\"utf-8\")\n",
    "    for row in all_tweets.itertuples():\n",
    "        if search_term.lower() in row[1].lower():\n",
    "            j+=1\n",
    "    return j\n",
    "# Now count multiple terms at once\n",
    "# The function counts both Arabic and English versions\n",
    "\n",
    "def count_category(search_dict):\n",
    "    i=0\n",
    "    for key in search_dict:\n",
    "        count = count_search_terms(search_dict[key])\n",
    "        count = count + count_search_terms(key)\n",
    "        i+=count\n",
    "        ##print key + \": \" + str(count)\n",
    "    ##print \"category total: \" + str(i)\n",
    "        \n",
    "# function decides if category is present\n",
    "def has_category(tweet_content, search_dict):\n",
    "    answer = False\n",
    "#     tweet_content = unicode(tweet_content, encoding=\"utf-8\")\n",
    "    for english_word in search_dict.keys():\n",
    "        if english_word.lower() in tweet_content.lower():\n",
    "            answer = True\n",
    "    for arabic_word in search_dict.values():\n",
    "        arabic_word = unicode(arabic_word, encoding=\"utf-8\")\n",
    "        if arabic_word in tweet_content:\n",
    "            answer = True\n",
    "    return answer\n",
    "\n",
    "# function checks every row and adds categories\n",
    "def fill_in_categories():\n",
    "    for tweet in all_tweets.itertuples():\n",
    "        idx = tweet[0]\n",
    "        content = all_tweets.loc[idx,'content']\n",
    "        if has_category(content, traffic_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'traffic'\n",
    "        elif has_category(content, transit_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'transit'\n",
    "        elif has_category(content, accident_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'accident'\n",
    "        elif has_category(content, parking_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'parking'\n",
    "        elif has_category(content, prayer_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'prayer'\n",
    "        elif has_category(content, fun_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'fun'\n",
    "        else:\n",
    "            all_tweets.loc[idx, 'category'] = 'none' \n",
    "            \n",
    "# function convert time format\n",
    "def time_converter(input_string):\n",
    "    ##orig_date = input_string[:-10] + input_string[-4:]\n",
    "    ##convert = time.strptime(orig_date, '%a %b %d %H:%M:%S %Y')\n",
    "    ##new_time = time.strftime(\"%A %I %p\",convert)\n",
    "    new_date = str(input_string[4:10])\n",
    "    new_hour = str(input_string[11:13])\n",
    "    return new_date, new_hour\n",
    "\n",
    "### for loop to print the csv file\n",
    "for m in range (20,28):\n",
    "    x= 280*3*m\n",
    "    y= x+280*3\n",
    "    print m\n",
    "    print (x,y)\n",
    "    df = pd.DataFrame()\n",
    "    for filename in all_files[x:y]:\n",
    "        ##print filename\n",
    "        new_path = \"json\"+\"/\" + str(filename)\n",
    "        df0 = pd.read_json(new_path)\n",
    "        df1 = df0.T\n",
    "        df = df.append(df1)\n",
    "    # reverse the columns and rows\n",
    "    all_tweets = df\n",
    "    print all_tweets.shape\n",
    "    # Add and drop columns, reset index\n",
    "    all_tweets['category'] = \"\"\n",
    "    all_tweets.reset_index(drop=True, inplace=True)\n",
    "    all_tweets.drop(['data_point','raw_source','tweet_id', 'user','user_location'],axis=1, inplace=True)\n",
    "    ## Count Categories\n",
    "    count_category(traffic_dict)\n",
    "    count_category(parking_dict)\n",
    "    count_category(accident_dict)\n",
    "    count_category(transit_dict)\n",
    "    count_category(prayer_dict)\n",
    "    count_category(fun_dict)\n",
    "    ## Fill in Categories\n",
    "    fill_in_categories()\n",
    "    \n",
    "## Filter to choose certain category\n",
    "    ###all_tweets_categorized = all_tweets[all_tweets['category']!= 'none']\n",
    "    ##df = all_tweets[all_tweets['category']== 'prayer']    \n",
    "    ## Change Time Format\n",
    "    df = all_tweets\n",
    "    for row in df.itertuples():\n",
    "        idx = int(row[0])\n",
    "        new_time = time_converter(df.loc[idx,'time'])\n",
    "        df.loc[idx,'Date'] = str(new_time[0])\n",
    "        df.loc[idx,'Hour'] = float(new_time[1])\n",
    "    # df.to_csv(\"df_\"+str(x)+\"_\"+str(y)+\".csv\", index=False, encoding='utf-8')\n",
    "    # print \"Done with Writing: \"+\"df_\"+str(x)+\"_\"+str(y)+\".csv\"\n",
    "    from collections import Counter\n",
    "    Counter(df['Date'])\n",
    "    df_new = pd.DataFrame()\n",
    "    df_new['Hour'] = \"\"\n",
    "    j=0\n",
    "    for i in dict.keys(Counter(df['Date'])):\n",
    "        for j in range(0,24):\n",
    "            ##print i + \", \" + \"Hour: \" +str(j)\n",
    "            count= np.sum((df['Date']==i) & (df['Hour']== j))\n",
    "            ##print count\n",
    "            df_new.loc[j,i] = float(count)\n",
    "            df_new.loc[j, 'Hour'] = j\n",
    "    # df_new.head(5)\n",
    "    df_new.to_csv(\"all_tweets/\"+\"df_new_\"+str(x)+\"_\"+str(y)+\".csv\", index=False, encoding='utf-8')\n",
    "    print \"Done Writing: \"+\"df_new_\"+str(x)+\"_\"+str(y)+\".csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
