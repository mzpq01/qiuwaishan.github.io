{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "path = 'twitter/'\n",
    "all_files = os.listdir(path)\n",
    "count_files = len(os.listdir(path))\n",
    "print count_files\n",
    "print type(all_files)\n",
    "print all_files[0]\n",
    "print all_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = 280*40\n",
    "print limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "df = pd.DataFrame()\n",
    "for filename in all_files:\n",
    "    i=i+1\n",
    "    if i <= limit:\n",
    "        ##print filename\n",
    "        new_path = \"twitter\"+\"/\" + str(filename)\n",
    "        df0 = pd.read_json(new_path)\n",
    "        df1 = df0.T\n",
    "        df = df.append(df1)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### df = pd.read_json('twitter/2015-10-07 22%3A16%3A58.283000tweets.json')\n",
    "# all_tweets is a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(df)\n",
    "print type(df)\n",
    "print df.dtypes.head(3)\n",
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reverse the columns and rows\n",
    "all_tweets = df\n",
    "print all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add and drop columns, reset index\n",
    "all_tweets['category'] = \"\"\n",
    "## all_tweets['user_from']= \"\"\n",
    "all_tweets.reset_index(drop=True, inplace=True)\n",
    "all_tweets.drop(['data_point','raw_source','tweet_id', 'user','user_location'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prayer_dict = {'pray':'صلى','prayer':'صلاة','praying':'صلاة','muslim':'مسلم','Islam':'الإسلام',\n",
    "               'mosque':'جامع','mosques':'جوامع','masjid':'مساجد','masjids':'مسجد',\n",
    "               'call to prayer':'اذان','muezzin':'مؤذن','holy':'مقدس',\n",
    "              'imam':'أئمة','imams':'امام','koran':'القرآن','chapter':'سور','verse':'آيات'}\n",
    "food_dict = {'food':'طعام','eating':'يتناول الطعام','falafel':'فلافل','shawarma':'الشاورما',\n",
    "            'starbucks':'ستاربكس','mcdonalds':'ماكدونالدز'}\n",
    "fun_dict = {'restaurant':'مطاعم','restaurants':'مطعم','park':'حدائق','theater':'سينمات','museum':'متاحف',\n",
    "           'bakery':'مخابز','gallery':'معرض','fair':'مهرجانات','zoo':'حديقة الحيوان','hotel':'فنادق',\n",
    "           'starbucks':'ستاربكس','mcdonalds':'ماكدونالدز'}\n",
    "parking_dict = {'stop':'يوقف','park':'وقف','parking lot':'موقف','parking':'مواقف','standing':'المواقف',\n",
    "               'street parking':'يركن','garage':'يجرّش'}\n",
    "traffic_dict = {'traffic':'مرور','underground':'سرا','crowd':'زحمة','crowds':'زحام','jammed':'اختناق',\n",
    "                'erupted':'نشبت','reroute':'تحويلة','bump':'مطب','pothole':'مطبات'}\n",
    "accident_dict = {'accident':'حادث','accidents':'حوادث','crashes':'حادثة','collision':'صدم','hit by':'صدمني',\n",
    "                 'detour':'انعفطت',\n",
    "                'wreck':'خربت','wreckage':'حطام'}\n",
    "transit_dict = {'bus':'باص','taxi':'تاكسي','taxis':'تاكسيات','cab':'تكسي','limo':'ليموزين','fare':'أجرة',\n",
    "                'cab fee':'اجرة','Careem':'كريم','Uber':'اوبر','driver':'سواق','chauffeur':'سائق','airport':'مطارات',\n",
    "                'public transit':'مواصلات'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for Arabic terms using unicode\n",
    "# It works on English too\n",
    "\n",
    "def count_search_terms(arabic_word):\n",
    "    j=0\n",
    "    search_term = unicode(arabic_word, encoding=\"utf-8\")\n",
    "    for row in all_tweets.itertuples():\n",
    "        if search_term.lower() in row[1].lower():\n",
    "            j+=1\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now count multiple terms at once\n",
    "# The function counts both Arabic and English versions\n",
    "\n",
    "def count_category(search_dict):\n",
    "    i=0\n",
    "    for key in search_dict:\n",
    "        count = count_search_terms(search_dict[key])\n",
    "        count = count + count_search_terms(key)\n",
    "        i+=count\n",
    "        print key + \": \" + str(count)\n",
    "    print \"category total: \" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_category(traffic_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_category(parking_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_category(accident_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_category(transit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_category(prayer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_category(fun_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function decides if category is present\n",
    "def has_category(tweet_content, search_dict):\n",
    "    answer = False\n",
    "#     tweet_content = unicode(tweet_content, encoding=\"utf-8\")\n",
    "    for english_word in search_dict.keys():\n",
    "        if english_word.lower() in tweet_content.lower():\n",
    "            answer = True\n",
    "    for arabic_word in search_dict.values():\n",
    "        arabic_word = unicode(arabic_word, encoding=\"utf-8\")\n",
    "        if arabic_word in tweet_content:\n",
    "            answer = True\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function checks every row and adds categories\n",
    "def fill_in_categories():\n",
    "    for tweet in all_tweets.itertuples():\n",
    "        idx = tweet[0]\n",
    "        content = all_tweets.loc[idx,'content']\n",
    "        if has_category(content, traffic_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'traffic'\n",
    "        elif has_category(content, transit_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'transit'\n",
    "        elif has_category(content, accident_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'accident'\n",
    "        elif has_category(content, parking_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'parking'\n",
    "        elif has_category(content, prayer_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'prayer'\n",
    "        elif has_category(content, fun_dict):\n",
    "            all_tweets.loc[idx, 'category'] = 'fun'\n",
    "        else:\n",
    "            all_tweets.loc[idx, 'category'] = 'none'            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fill_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_converter(input_string):\n",
    "    ##orig_date = input_string[:-10] + input_string[-4:]\n",
    "    ##convert = time.strptime(orig_date, '%a %b %d %H:%M:%S %Y')\n",
    "    ##new_time = time.strftime(\"%A %I %p\",convert)\n",
    "    new_date = str(input_string[4:10])\n",
    "    new_hour = str(input_string[11:13])\n",
    "    return new_date, new_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print time_converter('Tue Oct 13 17:08:31 +0000 2015')\n",
    "print time_converter(all_tweets.loc[16,'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in all_tweets.itertuples():\n",
    "    idx = int(row[0])\n",
    "    new_time = time_converter(all_tweets.loc[idx,'time'])\n",
    "    all_tweets.loc[idx,'Date'] = str(new_time[0])\n",
    "    all_tweets.loc[idx,'Hour'] = float(new_time[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets.to_csv('all_tweets.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.sum(df['category'] == \"transit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = all_tweets\n",
    "# Group the edges by their source\n",
    "grouped_sources = df['Hour'].groupby(df['Date'])\n",
    "## count and combine\n",
    "edges_per_node = grouped_sources.count()\n",
    "print edges_per_node\n",
    "\n",
    "from collections import Counter\n",
    "Counter(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()\n",
    "j=0\n",
    "for i in dict.keys(Counter(df['Date'])):\n",
    "    for j in range(0,24):\n",
    "        ##print i + \", \" + \"Hour: \" +str(j)\n",
    "        count= np.sum((df['Date']==i) & (df['Hour']== j))\n",
    "        ##print count\n",
    "        df_new.loc[j,i] = float(count)\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new.to_csv('df_new.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets_categorized = all_tweets[all_tweets['category']!= 'none']\n",
    "print len(all_tweets_categorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets_categorized.reset_index(inplace=True, drop=True)\n",
    "all_tweets_categorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets_categorized.to_csv('all_tweets_categorized.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
