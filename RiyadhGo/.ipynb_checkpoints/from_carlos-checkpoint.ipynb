{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# This allows plots to appear on the IPython notebook.\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/riyadh_route_edges_am.txt\", sep=\" \", index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's define an empty undirected graph.\n",
    "RG = nx.Graph()\n",
    "\n",
    "# We also define the values for the edge attributes\n",
    "keys = ['volume', 'capacity', 'voc', 'degree', 'free_travel_time', 'travel_time']\n",
    "for row in df.itertuples(index=False):    \n",
    "    values = row[2:]\n",
    "    # We create a dictionary with the keys and row values\n",
    "    edge_attributes = dict(zip(keys, values))\n",
    "    my_tuple = (row[0], row[1])\n",
    "    # We add the edge to the graph\n",
    "    RG.add_edge(*my_tuple, attr_dict=edge_attributes)\n",
    "# Analysis the degrees use nx.degree() function        \n",
    "degrees = nx.degree(RG)\n",
    "print degrees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If I pick any two intersections, is it possible to find a route\n",
    "# between them? Check if the network is connected.\n",
    "print \"*Is the road network connected? \"+ str(nx.is_connected(RG)),\n",
    "\n",
    "# Here we generate all the shortest paths from the graph. Records in Dictionary \"paths\"\n",
    "# paths = nx.shortest_path(RG)\n",
    "\n",
    "# Since all the paths are stored in a big dictionary, we can access the shortest path of every node by its index or name!\n",
    "# # We can start by printing all the paths from node_id 1\n",
    "# print \"*All Paths starting from Node '1':\"\n",
    "# print str(paths[1]) ## \\\"paths\\\" is a dictionary with format of {node_id:}\n",
    "# print \"\\n\"\n",
    "\n",
    "\n",
    "# # Since within node_id 1, it connects to node_id 9950, we can count the number of nodes that exist between both\n",
    "# print \"Count Paths (length) from Node'1' to Node'9950': \" + str(len(paths[1][9950]))\n",
    "# print \"Namely: \" + str(paths[1][9950])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "node_list = [1]\n",
    "for start in node_list:\n",
    "    print \"*1. Start Node\" + str(start) \n",
    "    path_dict = {start:[]}\n",
    "    for end in RG.nodes():\n",
    "        try:\n",
    "            short_path = nx.dijkstra_path(RG, start, end, weight='travel_time')\n",
    "            path_dict[start].append({end:short_path})\n",
    "            print \"[start, End]: \" + str([start, end])\n",
    "        except:\n",
    "            pass\n",
    "    ##print path_dict\n",
    "    with open(\"Json/\"+str(start)+\".txt\", \"w\") as text_file:\n",
    "        text_file.write(json.dumps(path_dict))\n",
    "        print \"Done writting with Start Node\" + str(start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print nx.single_source_shortest_path(RG, 1, cutoff=50)\n",
    "\n",
    "import json\n",
    "node_list = [1,2,50,90]\n",
    "for start in RG.nodes()[:1000]:\n",
    "    short_path = nx.single_source_shortest_path(RG, start, cutoff=50)\n",
    "    with open(\"Json/cutoff/\"+str(start)+\".txt\", \"w\") as text_file:\n",
    "        text_file.write(json.dumps(path_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import json, Read riyadh network node data to get st_x, st_y (Lng, Lat)\n",
    "import json\n",
    "Nodes = pd.read_csv(\"data/riyadh_nodes.txt\", sep=\" \") ## <nrows> define the total rows that are read\n",
    "print \"* Total Nodes Numbers read is: \" + str(len(Nodes)) + \"\\n\"\n",
    "Nodes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now construct the multi-tier dictionary structures.\n",
    "# Build the 1st tier dictionary, called \\\"geoDataSet\\\".\\n\",\n",
    "geoDataSet  = {}\n",
    "geoDataSet[\"type\"] = \"FeatureCollection\"\n",
    "geoDataSet[\"features\"] = []\n",
    "\n",
    "# Build a dictionary \"Coordinate\" {id:[st_x,st_y]} that join node id with st_x and st_y. \n",
    "Coordinate = {}\n",
    "for i in range(len(Nodes[\"id\"])):  # i =0,1,2,...    \n",
    "    idx = Nodes[\"id\"][i]           # idx = 1,2,3,... In fact 'idx' is 'id' in dataframe \"Nodes\"\n",
    "    Coordinate[idx]=[Nodes[\"st_x\"][i],Nodes[\"st_y\"][i]]\n",
    "\n",
    "print \"Length of dict 'Coordinate': \" + str(len(Coordinate)) ## Test Print\n",
    "print Coordinate[50]  ## Test Print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Coordinate)):         # i =0,1,2,...,    \n",
    "    id_o = Nodes[\"id\"][i]                  # idx = 1,2,3,... In fact 'idx' is 'id' of dataframe \"Nodes\"\n",
    "    print \"1* When i= \"+str(i)+ \", Orientation Node= \"+str(id_o)\n",
    "    steps = len(paths[id_o].keys())  # Count how many successful lines connected to a node, including itself\n",
    "    if steps >1:\n",
    "        print \"2* All Paths to Ori_node are \"+str(paths[id_o])  # when idx=1, len(paths[idx])=3\n",
    "        ###print len(paths[idx].keys())       # when idx=1, len(path[idx].keys())=3\n",
    "        destination = [] # Define a list \"destination\" [] that use to record all the destinations\n",
    "        #print paths[idx]\n",
    "        #print Coordinate[idx]\n",
    "\n",
    "        ## Get all the nodes id that connect with node i.\n",
    "        for key in paths[id_o]: # when idx=1,paths[1]={1:[1],2:[1, 2],5748:[1, 5748]}, key=1,then 2,then 5748       \n",
    "            destination.append(key)               \n",
    "        print \"3* Total destination is\"+ str(destination)+\"\\n\"\n",
    "\n",
    "        for index in range(steps):        \n",
    "            id_des = destination[index]\n",
    "            print \"4.1** When index= \" + str(index)+\"ï¼Œ Destination Node= \" + str(id_des)\n",
    "            tmp_dict = {}\n",
    "            tmp_dict[\"type\"] = \"Feature\"\n",
    "            tmp_dict[\"geometry\"] = {}\n",
    "            tmp_dict[\"geometry\"][\"type\"] = \"LineString\"\n",
    "            tmp_dict[\"geometry\"][\"coordinates\"] = []        \n",
    "            tmp_coor=[Coordinate[id_o]] ## Already insert one origin point to avoid single point situation\n",
    "            ##print \"4.2** O_Node_\"+str(id_des) +\"'s coordination is\"+ str(Coordinate[id_o])     \n",
    "            for x in paths[id_o][id_des]:           \n",
    "                tmp_coor.append(Coordinate[x])            \n",
    "            ##print \"4.3** Temporary Destination List=\" + str(tmp_coor)        \n",
    "            tmp_dict[\"geometry\"][\"coordinates\"].append(tmp_coor)\n",
    "            ##print \"4.4** tmp_dict are: \"+str(tmp_dict)+\"\\n\"      \n",
    "            geoDataSet[\"features\"].append(tmp_dict)\n",
    "\n",
    "        ##print \"4*\" + str(geoDataSet)+ \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dumps(geoDataSet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
