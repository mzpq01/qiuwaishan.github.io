{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Seaborn\n",
    "import seaborn as sns\n",
    "# This allows plots to appear on the IPython notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eid\n",
      "101      0.268594\n",
      "20415    1.238560\n",
      "Name: travel_time, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>volume</th>\n",
       "      <th>capacity</th>\n",
       "      <th>voc</th>\n",
       "      <th>degree</th>\n",
       "      <th>free_travel_time</th>\n",
       "      <th>travel_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>67.222</td>\n",
       "      <td>2850</td>\n",
       "      <td>0.023587</td>\n",
       "      <td>158</td>\n",
       "      <td>0.268594</td>\n",
       "      <td>0.268594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source  target  volume  capacity       voc  degree  free_travel_time  \\\n",
       "eid                                                                         \n",
       "101       1       2  67.222      2850  0.023587     158          0.268594   \n",
       "\n",
       "     travel_time  \n",
       "eid               \n",
       "101     0.268594  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/riyadh_route_edges_am.txt\", sep=\" \", index_col=0)\n",
    "print df[\"travel_time\"].head(2)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*1. [(1, 2), (1, 5748), (1, 9437)]\n",
      "*2. [1, 2, 3]\n",
      "*3. [(1, 2), (1, 5748), (1, 9437), (2, 7438), (2, 9950)]**[(2, 7438), (2, 9950)]\n",
      "*4. {'capacity': 2850, 'degree': 369, 'voc': 0.073342999999999992, 'volume': 209.02700000000002, 'travel_time': 0.268596, 'free_travel_time': 0.268594}\n",
      "*5. 0.268596 0.268596\n",
      "*6. {}\n"
     ]
    }
   ],
   "source": [
    "# Let's define an empty undirected graph \"RG\".\n",
    "RG = nx.Graph()\n",
    "# We also define the values dictionary for the \"edge attributes\"\n",
    "keys = ['volume', 'capacity', 'voc', 'degree', 'free_travel_time', 'travel_time']\n",
    "for row in df.itertuples(index=False):    \n",
    "    values = row[2:]    \n",
    "    # We create a dictionary \"edge_attributes\" with the keys and row values\n",
    "    edge_attributes = dict(zip(keys, values))    \n",
    "    my_tuple = (row[0], row[1])   \n",
    "    # We add the edge to the graph use \"add_edge\" function\n",
    "    RG.add_edge(*my_tuple, attr_dict=edge_attributes)\n",
    "\n",
    "# ******How to call nodes, edges, and their attributes******************************************\n",
    "print \"*1. \"+str(RG.edges(1))     # call all edges starting from node_1\n",
    "print \"*2. \"+str(RG.nodes()[:3])  # call first 3 nodes \n",
    "print \"*3. \"+str(RG.edges()[:5]) + \"**\" + str(RG.edges()[3:5])\n",
    "print \"*4. \"+str(RG[1][2])   # call edge (1,2)\n",
    "print \"*5. \"+str(RG[1][2][\"travel_time\"]) +\" \"+ str(RG[2][1][\"travel_time\"]) # call edge (1,2) attribute \"travel_time\"\n",
    "print \"*6. \"+str(RG.node[1]) # call node_1 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()                  # build an empty graph G by nx.Graph() function\n",
    "G.add_edges_from(RG.edges(1))   # add all edges start from node_1 to G graph as G's edges\n",
    "degrees_G = nx.degree(G)        # caculate degrees of nodes in G graph\n",
    "node_sizes = [v*100 for v in degrees_G.values()] # degrees_G.values() request all the values in dictionary degrees_G\n",
    "node_colors = range(len(G.nodes()))\n",
    "weight = [w*0.03 for w in node_sizes]\n",
    "\n",
    "plt.figure(figsize=(8,2))       # build an empty graphy plot\n",
    "P = nx.spring_layout(G);        # generate random layout position for nodes in graph G plot\n",
    "\n",
    "nx.draw(G, pos=P, node_size=node_sizes,width=weight,node_color=\"red\")\n",
    "nx.draw_networkx_labels(G,pos=P) # semicolon suppresses output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_x</th>\n",
       "      <th>st_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.849302</td>\n",
       "      <td>24.701475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         st_x       st_y\n",
       "id                      \n",
       "1   46.849302  24.701475"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe of node with coordinates\n",
    "nodes_df = pd.read_csv(\"data/riyadh_nodes.txt\", sep=\" \", index_col=0)\n",
    "nodes_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coordinate': (46.849302248324101, 24.701475446932697)}\n",
      "46.8493022483\n"
     ]
    }
   ],
   "source": [
    "loc_dict = {}\n",
    "for node_id in RG.nodes():\n",
    "    # df.loc[row_indexer,column_indexer]; df.loc[x,y] is a locator look for certain row x and column y\n",
    "    loc_dict[node_id] = (float(nodes_df.loc[[node_id]]['st_x']), float(nodes_df.loc[[node_id]]['st_y']))\n",
    "    # or the other way round, just simply call the dataframe by column name and row number\n",
    "    RG.node[node_id][\"coordinate\"] = (nodes_df['st_x'][node_id], nodes_df['st_y'][node_id])\n",
    "\n",
    "print RG.node[1]                # call attribute dictionary of node_1\n",
    "print RG.node[1][\"coordinate\"]  # call value of key coordinate of node_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.0, 2: 0.002306, 3: 0.314302, 4: 0.314429, 5: 0.104137, 6: 0.103287, 7: 0.16836, 8: 0.168488, 9: 0.366636, 10: 0.37129}\n",
      "[(1, 0.0), (2, 0.002306), (6, 0.103287), (5, 0.104137), (7, 0.16836), (8, 0.168488), (3, 0.314302), (4, 0.314429), (9, 0.366636), (10, 0.37129)]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Now we caculate the Manhattan District\n",
    "import operator\n",
    "start_node = [1]\n",
    "distance = {}\n",
    "for i in start_node:\n",
    "    for node_id in RG.nodes()[:10]:\n",
    "        distance[node_id] = round(abs(RG.node[i][\"coordinate\"][0] -RG.node[node_id][\"coordinate\"][0])\n",
    "        +abs(RG.node[i][\"coordinate\"][1] -RG.node[node_id][\"coordinate\"][1]),6)\n",
    "\n",
    "print distance\n",
    "sorted_distance = sorted(distance.items(), key = operator.itemgetter(1))\n",
    "print sorted_distance\n",
    "print sorted_distance[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analysis the degrees, and centrality use \"nx.degree()\" and \"nx.degree_centrality\" function        \n",
    "degrees = nx.degree(RG)\n",
    "centralities= nx.degree_centrality(RG)\n",
    "# degrees, centralities are dictionary, we need to call their all values as new lists\n",
    "node_centrality=[round((centralities[u]*10000),2) for u in centralities]\n",
    "node_degree = [i for i in degrees.values()]\n",
    "\n",
    "#print node_centrality\n",
    "#print node_degree\n",
    "print \"Done with process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****Right way to call edge, node attributes as visualization reference****\n",
    "# colors = [G[u][v]['color'] for u,v in edges]\n",
    "# weights = [G[u][v]['weight'] for u,v in edges]\n",
    "# nx.draw(G, pos, edges=edges, edge_color=colors, width=weights)\n",
    "\n",
    "import matplotlib.cm as cm # import the colormap library\n",
    "\n",
    "node_colors = range(len(RG.nodes())) # plt.cm.coolwarm() is a function change value to color from cool-warm\n",
    "node_sizes = node_centrality\n",
    "edges = RG.edges()\n",
    "weights = [RG[u][v][\"volume\"]*0.0009 for u,v in edges]\n",
    "edge_colors = plt.cm.coolwarm(np.log(np.log(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "nx.draw(RG, pos=loc_dict, node_size=node_sizes, width=weights, node_color=node_colors, edge_color = edge_colors);\n",
    "##nx.draw_networkx_labels(RG, pos=loc_dict); # semicolon suppresses output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If I pick any two intersections, is it possible to find a route\n",
    "# between them? Check if the network is connected.\n",
    "print \"*Is the road network connected? \"+ str(nx.is_connected(RG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use nx.dijkstra_path(G,node_start,node_end, weight) to caculate shortest paths\n",
    "import json\n",
    "node_list = [1]\n",
    "for start in node_list:\n",
    "    ##print \"*1. Start Node: \" + str(start) \n",
    "    path_dict = {start:[]}\n",
    "    for end in RG.nodes()[:9000]:  # [:x] control how many nodes in loop as end_point\n",
    "        try:\n",
    "            short_path = nx.dijkstra_path(RG, start, end, weight='travel_time')\n",
    "            path_dict[start].append({end:short_path})\n",
    "            ##print \"*1.1 [start, End]: \" + str([start, end])\n",
    "            ##print \"*1.2 Shortest path is: \"+str(short_path)\n",
    "            ##print \"*1.3 Record dictionary is: \"+str(path_dict)\n",
    "            ##print \"\\n\"\n",
    "        except:\n",
    "            pass\n",
    "    ##print path_dict\n",
    "    with open(\"Json/\"+str(start)+\".txt\", \"w\") as text_file:\n",
    "        text_file.write(json.dumps(path_dict))\n",
    "        print \"Done writting with Start Node: \" + str(start) + \"\\n\"\n",
    "\n",
    "#print path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_all=[1]\n",
    "\n",
    "# Let's define a new empty undirected graph \"Shortest_RG\".\n",
    "Shortest_RG = nx.Graph()\n",
    "\n",
    "sum_time = {}\n",
    "tmp_edges = []\n",
    "\n",
    "for i in start_all:\n",
    "    for j in range(len(path_dict[i])):        \n",
    "        tmp_dict= path_dict[i][j]\n",
    "        tmp= tmp_dict.values()\n",
    "        tmp_list= tmp[0]\n",
    "        #print \"1* i=\"+str(i) + \", j=\"+str(j)+ \", \"+str(tmp_dict)+\", list length=\"+str(len(tmp_list))        \n",
    "        time_list = []\n",
    "        if len(tmp_list) > 1:\n",
    "            for x in range(len(tmp_list)-1):\n",
    "                o_id = tmp_list[x]\n",
    "                d_id = tmp_list[x+1]\n",
    "                ##print o_id, d_id                    \n",
    "                time_list.append(round(RG[o_id][d_id][\"travel_time\"],2))                                \n",
    "                new_edge_attr = RG[o_id][d_id]\n",
    "                ##print new_edge_attr\n",
    "                Shortest_RG.add_edge(*(o_id,d_id), attr_dict= new_edge_attr)\n",
    "                Shortest_RG[o_id][d_id][\"sum_time\"]= round(sum(time_list),2)\n",
    "                sum_time[(o_id,d_id)] = round(sum(time_list),2)\n",
    "            ##print \"2* time_list= \" +str(time_list)\n",
    "            ##print \"3* sum_time= \" +str(sum_time)\n",
    "        ##print \"\\n\"\n",
    "print \"Done with Caculation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we can add node coordinates\n",
    "loc_dict = {}\n",
    "for node_index in Shortest_RG.nodes():\n",
    "    ##print node_index\n",
    "    loc_dict[node_index] = RG.node[node_index][\"coordinate\"]\n",
    "    Shortest_RG.node[node_index][\"coordinate\"] = RG.node[node_index][\"coordinate\"]\n",
    "    ##print loc_dict[node_index]\n",
    "\n",
    "print Shortest_RG.edge[1][9437]\n",
    "print \"\\n\"\n",
    "print Shortest_RG[1][2]\n",
    "print \"\\n\"\n",
    "#print Shortest_RG.edges()\n",
    "print \"\\n\"\n",
    "print Shortest_RG.node[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning a new function \"subgraph\"\n",
    "# Shortest_RG = RG.subgraph(path_all_id)\n",
    "##print Shortest_RG[1][9437]\n",
    "##print \"\\n\"\n",
    "##print Shortest_RG.edges()\n",
    "##print \"\\n\"\n",
    "##print Shortest_RG.node[1]\n",
    "##print \"\\n\"\n",
    "# Caculate the degrees of each node\n",
    "##degrees = []\n",
    "##degrees = nx.degree(Shortest_RG)\n",
    "##print degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "degrees_s = nx.degree(Shortest_RG)\n",
    "node_sizes = []\n",
    "for i in Shortest_RG.nodes():\n",
    "    node_sizes.append(degrees[i])\n",
    "\n",
    "node_colors = range(len(Shortest_RG.nodes()))\n",
    "\n",
    "edges = Shortest_RG.edges()\n",
    "weights = [30/Shortest_RG[u][v][\"sum_time\"] for u,v in edges]\n",
    "#edge_colors = [Shortest_RG[u][v][\"volume\"] for u,v in edges]\n",
    "edge_colors = plt.cm.coolwarm(np.log(weights))\n",
    "\n",
    "##print node_sizes\n",
    "##print node_colors\n",
    "##print edges\n",
    "##print weights\n",
    "##print edge_colors\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "nx.draw(Shortest_RG, pos=loc_dict, node_size=0.1, node_color=node_colors, width=weights, edge_color=edge_colors);\n",
    "#nx.draw_networkx_labels(Shortest_RG,pos=loc_dict); # semicolon suppresses output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_time = [Shortest_RG[u][v][\"sum_time\"] for u,v in edges]\n",
    "print sorted(sum_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import json, Read riyadh network node data to get st_x, st_y (Lng, Lat)\n",
    "import json\n",
    "Nodes = pd.read_csv(\"data/riyadh_nodes.txt\", sep=\" \") ## <nrows> define the total rows that are read\n",
    "print \"* Total Nodes Numbers read is: \" + str(len(Nodes)) + \"\\n\"\n",
    "Nodes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now construct the multi-tier dictionary structures.\n",
    "# Build the 1st tier dictionary, called \\\"geoDataSet\\\".\\n\",\n",
    "geoDataSet  = {}\n",
    "geoDataSet[\"type\"] = \"FeatureCollection\"\n",
    "geoDataSet[\"features\"] = []\n",
    "\n",
    "# Build a dictionary \"Coordinate\" {id:[st_x,st_y]} that join node id with st_x and st_y. \n",
    "Coordinate = {}\n",
    "for i in range(len(Nodes[\"id\"])):  # i =0,1,2,...    \n",
    "    idx = Nodes[\"id\"][i]           # idx = 1,2,3,... In fact 'idx' is 'id' in dataframe \"Nodes\"\n",
    "    Coordinate[idx]=[Nodes[\"st_x\"][i],Nodes[\"st_y\"][i]]\n",
    "\n",
    "print \"Length of dict 'Coordinate': \" + str(len(Coordinate)) ## Test Print\n",
    "print Coordinate[50]  ## Test Print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(Coordinate)):         # i =0,1,2,...,    \n",
    "    id_o = Nodes[\"id\"][i]                  # idx = 1,2,3,... In fact 'idx' is 'id' of dataframe \"Nodes\"\n",
    "    print \"1* When i= \"+str(i)+ \", Orientation Node= \"+str(id_o)\n",
    "    steps = len(paths[id_o].keys())  # Count how many successful lines connected to a node, including itself\n",
    "    if steps >1:\n",
    "        print \"2* All Paths to Ori_node are \"+str(paths[id_o])  # when idx=1, len(paths[idx])=3\n",
    "        ###print len(paths[idx].keys())       # when idx=1, len(path[idx].keys())=3\n",
    "        destination = [] # Define a list \"destination\" [] that use to record all the destinations\n",
    "        #print paths[idx]\n",
    "        #print Coordinate[idx]\n",
    "\n",
    "        ## Get all the nodes id that connect with node i.\n",
    "        for key in paths[id_o]: # when idx=1,paths[1]={1:[1],2:[1, 2],5748:[1, 5748]}, key=1,then 2,then 5748       \n",
    "            destination.append(key)               \n",
    "        print \"3* Total destination is\"+ str(destination)+\"\\n\"\n",
    "\n",
    "        for index in range(steps):        \n",
    "            id_des = destination[index]\n",
    "            print \"4.1** When index= \" + str(index)+\"， Destination Node= \" + str(id_des)\n",
    "            tmp_dict = {}\n",
    "            tmp_dict[\"type\"] = \"Feature\"\n",
    "            tmp_dict[\"geometry\"] = {}\n",
    "            tmp_dict[\"geometry\"][\"type\"] = \"LineString\"\n",
    "            tmp_dict[\"geometry\"][\"coordinates\"] = []        \n",
    "            tmp_coor=[Coordinate[id_o]] ## Already insert one origin point to avoid single point situation\n",
    "            ##print \"4.2** O_Node_\"+str(id_des) +\"'s coordination is\"+ str(Coordinate[id_o])     \n",
    "            for x in paths[id_o][id_des]:           \n",
    "                tmp_coor.append(Coordinate[x])            \n",
    "            ##print \"4.3** Temporary Destination List=\" + str(tmp_coor)        \n",
    "            tmp_dict[\"geometry\"][\"coordinates\"].append(tmp_coor)\n",
    "            ##print \"4.4** tmp_dict are: \"+str(tmp_dict)+\"\\n\"      \n",
    "            geoDataSet[\"features\"].append(tmp_dict)\n",
    "\n",
    "##print \"4*\" + str(geoDataSet)+ \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print nx.single_source_shortest_path(RG, 1, cutoff=50)\n",
    "\n",
    "import json\n",
    "node_list = [1,2,50,90]\n",
    "for start in RG.nodes()[:1000]:\n",
    "    short_path = nx.single_source_shortest_path(RG, start, cutoff=50)\n",
    "    with open(\"Json/cutoff/\"+str(start)+\".txt\", \"w\") as text_file:\n",
    "        text_file.write(json.dumps(path_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import json, Read riyadh network node data to get st_x, st_y (Lng, Lat)\n",
    "import json\n",
    "Nodes = pd.read_csv(\"data/riyadh_nodes.txt\", sep=\" \") ## <nrows> define the total rows that are read\n",
    "print \"* Total Nodes Numbers read is: \" + str(len(Nodes)) + \"\\n\"\n",
    "Nodes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now construct the multi-tier dictionary structures.\n",
    "# Build the 1st tier dictionary, called \\\"geoDataSet\\\".\\n\",\n",
    "geoDataSet  = {}\n",
    "geoDataSet[\"type\"] = \"FeatureCollection\"\n",
    "geoDataSet[\"features\"] = []\n",
    "\n",
    "# Build a dictionary \"Coordinate\" {id:[st_x,st_y]} that join node id with st_x and st_y. \n",
    "Coordinate = {}\n",
    "for i in range(len(Nodes[\"id\"])):  # i =0,1,2,...    \n",
    "    idx = Nodes[\"id\"][i]           # idx = 1,2,3,... In fact 'idx' is 'id' in dataframe \"Nodes\"\n",
    "    Coordinate[idx]=[Nodes[\"st_x\"][i],Nodes[\"st_y\"][i]]\n",
    "\n",
    "print \"Length of dict 'Coordinate': \" + str(len(Coordinate)) ## Test Print\n",
    "print Coordinate[50]  ## Test Print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(Coordinate)):         # i =0,1,2,...,    \n",
    "    id_o = Nodes[\"id\"][i]                  # idx = 1,2,3,... In fact 'idx' is 'id' of dataframe \"Nodes\"\n",
    "    print \"1* When i= \"+str(i)+ \", Orientation Node= \"+str(id_o)\n",
    "    steps = len(paths[id_o].keys())  # Count how many successful lines connected to a node, including itself\n",
    "    if steps >1:\n",
    "        print \"2* All Paths to Ori_node are \"+str(paths[id_o])  # when idx=1, len(paths[idx])=3\n",
    "        ###print len(paths[idx].keys())       # when idx=1, len(path[idx].keys())=3\n",
    "        destination = [] # Define a list \"destination\" [] that use to record all the destinations\n",
    "        #print paths[idx]\n",
    "        #print Coordinate[idx]\n",
    "\n",
    "        ## Get all the nodes id that connect with node i.\n",
    "        for key in paths[id_o]: # when idx=1,paths[1]={1:[1],2:[1, 2],5748:[1, 5748]}, key=1,then 2,then 5748       \n",
    "            destination.append(key)               \n",
    "        print \"3* Total destination is\"+ str(destination)+\"\\n\"\n",
    "\n",
    "        for index in range(steps):        \n",
    "            id_des = destination[index]\n",
    "            print \"4.1** When index= \" + str(index)+\"， Destination Node= \" + str(id_des)\n",
    "            tmp_dict = {}\n",
    "            tmp_dict[\"type\"] = \"Feature\"\n",
    "            tmp_dict[\"geometry\"] = {}\n",
    "            tmp_dict[\"geometry\"][\"type\"] = \"LineString\"\n",
    "            tmp_dict[\"geometry\"][\"coordinates\"] = []        \n",
    "            tmp_coor=[Coordinate[id_o]] ## Already insert one origin point to avoid single point situation\n",
    "            ##print \"4.2** O_Node_\"+str(id_des) +\"'s coordination is\"+ str(Coordinate[id_o])     \n",
    "            for x in paths[id_o][id_des]:           \n",
    "                tmp_coor.append(Coordinate[x])            \n",
    "            ##print \"4.3** Temporary Destination List=\" + str(tmp_coor)        \n",
    "            tmp_dict[\"geometry\"][\"coordinates\"].append(tmp_coor)\n",
    "            ##print \"4.4** tmp_dict are: \"+str(tmp_dict)+\"\\n\"      \n",
    "            geoDataSet[\"features\"].append(tmp_dict)\n",
    "\n",
    "        ##print \"4*\" + str(geoDataSet)+ \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dumps(geoDataSet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
